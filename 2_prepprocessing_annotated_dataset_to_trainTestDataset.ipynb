{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda activate huggingface_env\n",
    "#conda info\n",
    "#ls\n",
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import spacy\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "pd.options.display.max_colwidth = 1000\n",
    "#ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1006, 8)\n"
     ]
    }
   ],
   "source": [
    "#load annotated dataset\n",
    "df = pd.read_excel('sentNeueClean7joined2_df.xlsx', sheet_name='Sheet1')\n",
    "\n",
    "\n",
    "#keep only rows where 'Annotierung' is not null\n",
    "df = df[df['Annotierung'].notnull()]\n",
    "df.head(3)\n",
    "#keep only columns 'name' 'vorname' 'Satz5' 'Annotierung'\n",
    "df = df[['name', 'vorname', 'name_mutter', 'vorname_mutter', 'name_vater', 'vorname_vater', 'Satz5', 'Annotierung']]\n",
    "#rename columns 'Annotierung' to 'label'\n",
    "df = df.rename(columns={'Annotierung': 'Gewalt'})\n",
    "#print number of rows and columns\n",
    "print(df.shape)\n",
    "#change type of column 'label' to int\n",
    "df['Gewalt'] = df['Gewalt'].astype(int)\n",
    "#print firts 3 rows\n",
    "df.head(3)\n",
    "#drop rows where 'label' is -1\n",
    "df = df[df['Gewalt'] != -1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consider Negation Outlier Corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sentence', 'label', 'label laet', 'predicted_label', 'loss', 'wrong', 'Bemerkungen', 'korrektur_label', 'korr_lab_dichot', 'diff_stdg_laet', 'Korr_besprochen']\n"
     ]
    }
   ],
   "source": [
    "# aussnegkorr_df = pd.read_excel('aussreisser_negation_20230614_2.xlsx', sheet_name='Sheet1')\n",
    "#neue  version von aussreisser_negation_20230614_2.xlsx mit David verglichen\n",
    "aussnegkorr_df = pd.read_excel('aussreisser_negation_20230614_2_anDavid_4_vergleich_Dragan_besprochen.xlsx', sheet_name='Sheet1')\n",
    "print(list(aussnegkorr_df.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Satz5', 'korrektur_label_alt', 'korrektur_label']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#keep only columns sentence and korrektur_label\n",
    "aussnegkorr_df = aussnegkorr_df[['sentence', 'korrektur_label', 'Korr_besprochen']]\n",
    "\n",
    "#create a new column 'korrektur_label2' and fill it with Korr_besprochen if Korr_besprochen is not null, else fill it with korrektur_label\n",
    "aussnegkorr_df['korrektur_label2'] = np.where(aussnegkorr_df['Korr_besprochen'].notnull(), aussnegkorr_df['Korr_besprochen'], aussnegkorr_df['korrektur_label'])\n",
    "#rename korrektur_label to korrektur_label_alt\n",
    "aussnegkorr_df = aussnegkorr_df.rename(columns={'korrektur_label': 'korrektur_label_alt'})\n",
    "#rename korrektur_label2 to korrektur_label\n",
    "aussnegkorr_df = aussnegkorr_df.rename(columns={'korrektur_label2': 'korrektur_label'})\n",
    "#drop column Korr_besprochen\n",
    "aussnegkorr_df = aussnegkorr_df.drop(columns=['Korr_besprochen'])\n",
    "\n",
    "#rename columns 'sentence' to 'Satz5'\n",
    "aussnegkorr_df = aussnegkorr_df.rename(columns={'sentence': 'Satz5'})\n",
    "print(list(aussnegkorr_df.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#join df and aussnegkorr_df on column 'sentence'\n",
    "df = df.join(aussnegkorr_df.set_index('Satz5'), on='Satz5')\n",
    "#show counts of all columns\n",
    "df.count()\n",
    "#print all Satz5 Gewalt korrektur_label columns where korrektur_label is not null\n",
    "# df[df['korrektur_label'].notnull()][['Satz5', 'Gewalt', 'korrektur_label']]\n",
    "#replace Gewalt with korrektur_label where korrektur_label is not null\n",
    "df.loc[df['korrektur_label'].notnull(), 'Gewalt'] = df['korrektur_label']\n",
    "# df[df['korrektur_label'].notnull()][['Satz5', 'Gewalt', 'korrektur_label']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replace pronouns with the names in the sentences \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"de_core_news_lg\")\n",
    "# doc = nlp(\"Der alte Vater hat jungen Jason nicht geschlagen und auch nicht misshandelt, es war ein schöner Tag.\")\n",
    "# # doc = nlp(\"Berlin sieht wie eine schöne Stadt aus\")\n",
    "# print(doc)\n",
    "\n",
    "# for token in doc:\n",
    "#     print(\"1\", token.lemma_, token.pos_, token.morph)\n",
    "\n",
    "# for chunk in doc.noun_chunks:\n",
    "#     print(\"2\", chunk.text, chunk.root.text, chunk.root.dep_,\n",
    "#             chunk.root.head.text)\n",
    "\n",
    "# for ent in doc.ents:\n",
    "#     print(\"3\", ent.text, ent.start_char, ent.end_char, ent.label_)\n",
    "# man muss den main_init mit den localen pfad vom de zip file ergänzen, siehe lib spacy vorlage\n",
    "# !python -m pip install coreferee\n",
    "# !python -m coreferee install de\n",
    "import coreferee\n",
    "# nlp = spacy.load('de_core_news_')\n",
    "nlp.add_pipe('coreferee')\n",
    "\n",
    "# correference resolution function for pronouns in a sentence\n",
    "def coreference_replacement(sentence):\n",
    "    if isinstance(sentence, str):\n",
    "        doc = nlp(sentence)\n",
    "        for x in range(len(doc._.coref_chains)):\n",
    "\n",
    "            for y in range(len(doc._.coref_chains[x])):\n",
    "\n",
    "                for z in range(len(doc._.coref_chains[x][y])):\n",
    "\n",
    "                    int=doc._.coref_chains[x][y][z]\n",
    "    \n",
    "                    replace_with=str(doc._.coref_chains.resolve(doc[int]))\n",
    "                    replace_with=replace_with.replace(\"[\",\" \")\n",
    "                    replace_with=replace_with.replace(\"]\",\" \")\n",
    "                    replace_with_strip=replace_with.strip()\n",
    "                    if replace_with=='None':\n",
    "\n",
    "                        pass\n",
    "                    else:\n",
    "                        for ent in doc.ents:\n",
    "                            \n",
    "                            if ent.text==replace_with_strip and (ent.label_==\"PER\" or ent.label_==\"MISC\"):\n",
    "                                if str(doc[doc._.coref_chains[x][y][z]]).lower() == \"er\" or str(doc[doc._.coref_chains[x][y][z]]).lower() == \"sie\":\n",
    "                                    sentence=sentence.replace(\" \"+str(doc[doc._.coref_chains[x][y][z]])+\" \", replace_with)\n",
    "#                                     print(doc[doc._.coref_chains[x][y][z]], doc[doc._.coref_chains[x][y][z]].pos_, replace_with)\n",
    "        return sentence\n",
    "    else: \n",
    "        return sentence\n",
    "    \n",
    "# create a new index column 'index' and set it as index\n",
    "df['index'] = df.index\n",
    "# repare this error \" # If we have a listlike key, _check_indexing_error will raise KeyError: 1\"\n",
    "df = df.reset_index(drop=True)\n",
    "# for i in range(100):    \n",
    "#      df.loc[i, \"Satz5_prep\"] = coreference_replacement(df.loc[i, \"Satz5\"])\n",
    "# for i in range(100):    \n",
    "#     df.loc[i, \"Satz5_prep\"] = coreference_replacement(df.loc[i, \"Satz5\"])  \n",
    "\n",
    "# run the coreference_replacement function on all rows in column 'Satz5' and save the result in column 'Satz5_prep'\n",
    "for i in range(len(df)):    \n",
    "    df.loc[i, \"Satz5_prep\"] = coreference_replacement(df.loc[i, \"Satz5\"])  \n",
    "    \n",
    "\n",
    "#print Satz5_prep and Satz5 for the first 30 rows\n",
    "# df[['Satz5_prep', 'Satz5']].head(30)\n",
    "# show me different strings between Satz5_prep and Satz5 for the first 30 rows\n",
    "# df[df['Satz5_prep'] != df['Satz5']][['Satz5_prep', 'Satz5']].head(30)\n",
    "# df_sample=df[:100]\n",
    "# df_sample[['s51', 's52', 's53', 's54', 's55', 's56']] = df_sample[\"Satz5_prep\"].str.split('|', 5, expand=True)\n",
    "# df_sample[['s51', 's52', 'Satz', 's53', 's54', 's55', 's56', 'Satz5_prep']][:10]\n",
    "\n",
    "# df[['s51', 's52', 's53', 's54', 's55', 's56']] = df[\"Satz5_prep\"].str.split('|', 5, expand=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replace the names of the client, mother of the child, and father with their labels (CLIENT, CM, CF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_replacement(sentence, keyword, replacement, similarity_rate=1):\n",
    "    if isinstance(keyword, str):\n",
    "        doc = nlp(sentence.lower())\n",
    "        doc1 = nlp(sentence)\n",
    "\n",
    "        doc_keyword=nlp(keyword.lower())\n",
    "\n",
    "        token2=doc_keyword[0]\n",
    "        for i in range(len(doc)):\n",
    "            token1=doc[i]\n",
    "            similarity2 = token1.similarity(token2)\n",
    "            if similarity2 >= similarity_rate:\n",
    "                sentence = sentence.replace(doc1[i].text, replacement)            \n",
    "        return sentence        \n",
    "    else: \n",
    "        return sentence\n",
    "        \n",
    "# for i in range(100):\n",
    "#     df.loc[i, \"Satz5_prep\"] = similarity_replacement(df.loc[i, \"s53\"], \n",
    "#     df.loc[i, \"VORNAME\"], \"KLIENT\", similarity_rate=0.9)\n",
    "\n",
    "# for i in range(100):    \n",
    "#     df.loc[i, \"Satz5_prep\"] = similarity_replacement(df.loc[i, \"Satz5_prep\"], \n",
    "#     df.loc[i, \"NAME_MUTTER\"], \"KINDSMUTTER\", similarity_rate=0.9)\n",
    "    \n",
    "# for i in range(100):    \n",
    "#     df.loc[i, \"Satz5_prep\"] = similarity_replacement(df.loc[i, \"Satz5_prep\"], \n",
    "#     df.loc[i, \"NAME_VATER\"] , \"KINDSVATER\", similarity_rate=0.9)  \n",
    "\n",
    "# for i in range(100):    \n",
    "#     df.loc[i, \"Satz5_prep\"] = (df.loc[i, \"Satz5_prep\"].replace( \n",
    "#     \"Frau KINDSVATER\" , \"KINDSMUTTER\"))  \n",
    "#     df.loc[i, \"Satz5_prep\"] = (df.loc[i, \"Satz5_prep\"].replace( \n",
    "#     \"Herr KINDSMUTTER\" , \"KINDSVATER\"))  \n",
    "#     df.loc[i, \"Satz5_prep\"] = (df.loc[i, \"Satz5_prep\"].replace( \n",
    "#     \"Herrn KINDSMUTTER\" , \"KINDSVATER\"))  \n",
    "#     df.loc[i, \"Satz5_prep\"] = (df.loc[i, \"Satz5_prep\"].replace( \n",
    "#     \"Herr KINDSVATER\" , \"KINDSVATER\"))  \n",
    "#     df.loc[i, \"Satz5_prep\"] = (df.loc[i, \"Satz5_prep\"].replace( \n",
    "#     \"Herrn KINDSVATER\" , \"KINDSVATER\"))  \n",
    "#     df.loc[i, \"Satz5_prep\"] = (df.loc[i, \"Satz5_prep\"].replace( \n",
    "#     \"Frau KINDSMUTTER\" , \"KINDSMUTTER\"))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-ad5d94f1384c>:11: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  similarity2 = token1.similarity(token2)\n"
     ]
    }
   ],
   "source": [
    "# for i in range(len(df)):\n",
    "# for i in range(100):\n",
    "#     print(\"Input:\", df.loc[i, \"Satz\"],\"\\n\",\n",
    "#           \"Client:\", df.loc[i, \"VORNAME\"], \"\\n\",\n",
    "#           \"Output:\", client_similarity_check(df.loc[i, \"Satz\"], df.loc[i, \"VORNAME\"]))\n",
    "for i in range(len(df)):\n",
    "    df.loc[i, \"Satz5_prep\"] = similarity_replacement(df.loc[i, \"Satz5_prep\"], \n",
    "    df.loc[i, \"vorname\"], \"KLIENT\", similarity_rate=0.8)\n",
    "\n",
    "for i in range(len(df)):    \n",
    "    df.loc[i, \"Satz5_prep\"] = similarity_replacement(df.loc[i, \"Satz5_prep\"], \n",
    "    df.loc[i, \"name_mutter\"], \"KINDSMUTTER\", similarity_rate=0.9)\n",
    "    \n",
    "for i in range(len(df)):    \n",
    "    df.loc[i, \"Satz5_prep\"] = similarity_replacement(df.loc[i, \"Satz5_prep\"], \n",
    "    df.loc[i, \"name_vater\"] , \"KINDSVATER\", similarity_rate=0.9)  \n",
    "#df[df['Satz5_prep'] != df['Satz5']][['Satz5_prep', 'Satz5']].head(30)\n",
    "# for i in range(len(df)):\n",
    "#     df.loc[i, \"Satz5_prep\"] = similarity_replacement(df.loc[i, \"Satz5_prep\"], \n",
    "#     df.loc[i, \"VORNAME\"], \"KLIENT\", similarity_rate=0.9)\n",
    "\n",
    "# for i in range(len(df)):    \n",
    "#     df.loc[i, \"Satz5_prep\"] = similarity_replacement(df.loc[i, \"Satz5_prep\"], \n",
    "#     df.loc[i, \"NAME_MUTTER\"], \"KINDSMUTTER\", similarity_rate=0.9)\n",
    "    \n",
    "# for i in range(len(df)):    \n",
    "#     df.loc[i, \"Satz5_prep\"] = similarity_replacement(df.loc[i, \"Satz5_prep\"], \n",
    "#     df.loc[i, \"NAME_VATER\"] , \"KINDSVATER\", similarity_rate=0.9) \n",
    "# cleanup the Satz5_prep column from the following strings\n",
    "for i in range(len(df)):\n",
    "    if isinstance(df.loc[i, \"Satz5_prep\"], str):\n",
    "        df.loc[i, \"Satz5_prep\"] = (df.loc[i, \"Satz5_prep\"].replace( \n",
    "        \"Frau KINDSVATER\" , \"KINDSMUTTER\"))  \n",
    "        df.loc[i, \"Satz5_prep\"] = (df.loc[i, \"Satz5_prep\"].replace( \n",
    "        \"Herr KINDSMUTTER\" , \"KINDSVATER\"))  \n",
    "        df.loc[i, \"Satz5_prep\"] = (df.loc[i, \"Satz5_prep\"].replace( \n",
    "        \"Herrn KINDSMUTTER\" , \"KINDSVATER\"))  \n",
    "        df.loc[i, \"Satz5_prep\"] = (df.loc[i, \"Satz5_prep\"].replace( \n",
    "        \"Herr KINDSVATER\" , \"KINDSVATER\"))  \n",
    "        df.loc[i, \"Satz5_prep\"] = (df.loc[i, \"Satz5_prep\"].replace( \n",
    "        \"Herrn KINDSVATER\" , \"KINDSVATER\"))  \n",
    "        df.loc[i, \"Satz5_prep\"] = (df.loc[i, \"Satz5_prep\"].replace( \n",
    "        \"Frau KINDSMUTTER\" , \"KINDSMUTTER\"))  \n",
    "# for i in range(len(df)):\n",
    "#     if isinstance(df.loc[i, \"Satz5_prep\"], str):\n",
    "#         df.loc[i, \"Satz5_prep\"] = (df.loc[i, \"Satz5_prep\"].replace( \n",
    "#         \"Frau KINDSVATER\" , \"KINDSMUTTER\"))  \n",
    "#         df.loc[i, \"Satz5_prep\"] = (df.loc[i, \"Satz5_prep\"].replace( \n",
    "#         \"Herr KINDSMUTTER\" , \"KINDSVATER\"))  \n",
    "#         df.loc[i, \"Satz5_prep\"] = (df.loc[i, \"Satz5_prep\"].replace( \n",
    "#         \"Herrn KINDSMUTTER\" , \"KINDSVATER\"))  \n",
    "#         df.loc[i, \"Satz5_prep\"] = (df.loc[i, \"Satz5_prep\"].replace( \n",
    "#         \"Herr KINDSVATER\" , \"KINDSVATER\"))  \n",
    "#         df.loc[i, \"Satz5_prep\"] = (df.loc[i, \"Satz5_prep\"].replace( \n",
    "#         \"Herrn KINDSVATER\" , \"KINDSVATER\"))  \n",
    "#         df.loc[i, \"Satz5_prep\"] = (df.loc[i, \"Satz5_prep\"].replace( \n",
    "#         \"Frau KINDSMUTTER\" , \"KINDSMUTTER\"))  \n",
    "# df[['Satz5', 'Satz5_prep', 'vorname', 'name_mutter', 'name_vater']][300:330]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gewalt</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0   count\n",
       "Gewalt       \n",
       "0         201\n",
       "1          90\n",
       "2          94\n",
       "3         184\n",
       "4         328\n",
       "5          90"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data3=df.copy()\n",
    "data3 = data3[data3.Gewalt != -1]\n",
    "pd.crosstab(index=data3['Gewalt'], columns='count')\n",
    "#drop rows with Gewalt equal to -1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previously created test dataset is filtered out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the excel tabel Test_weitereBegriffe_Annotiert_20230607.xlsx and save it as a dataframe\n",
    "data4 = pd.read_excel(\"Test_weitereBegriffe_Annotiert_20230607.xlsx\", sheet_name=\"Sheet1\")\n",
    "#keep only the row Satz5\n",
    "data4 = data4[['Satz5']]\n",
    "#create column drop and set it to 1\n",
    "data4['drop'] = 1\n",
    "#merge data3 and data4 on Satz5\n",
    "data3 = pd.merge(data3, data4, on='Satz5', how='left')\n",
    "\n",
    "\n",
    "\n",
    "#keep only the rows with drop is equal to null\n",
    "data3 = data3[data3['drop'].isnull()]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#create a dataframe with name train from data3\n",
    "train = data3.copy()\n",
    "pd.crosstab(index=data3['Gewalt'], columns='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Der Befehl \"stop\" ist entweder falsch geschrieben oder\n",
      "konnte nicht gefunden werden.\n"
     ]
    }
   ],
   "source": [
    "# 0 labels\n",
    "!stop do this only once\n",
    "# label_0=data3['Gewalt']==0\n",
    "# data3_0=data3[label_0]\n",
    "# train_0, test_0 = train_test_split(data3_0, test_size=50, random_state=42)\n",
    "# # 1 labels\n",
    "# label_1=data3['Gewalt']==1\n",
    "# data3_1=data3[label_1]\n",
    "# train_1, test_1 = train_test_split(data3_1, test_size=25, random_state=42)\n",
    "# # 2 labels\n",
    "# label_2=data3['Gewalt']==2\n",
    "# data3_2=data3[label_2]\n",
    "# train_2, test_2 = train_test_split(data3_2, test_size=25, random_state=42)\n",
    "# # 3 labels\n",
    "# label_3=data3['Gewalt']==3\n",
    "# data3_3=data3[label_3]\n",
    "# train_3, test_3 = train_test_split(data3_3, test_size=50, random_state=42)\n",
    "# # 4 labels\n",
    "# label_4=data3['Gewalt']==4\n",
    "# data3_4=data3[label_4]\n",
    "# train_4, test_4 = train_test_split(data3_4, test_size=50, random_state=42)\n",
    "# # 5 labels\n",
    "# label_5=data3['Gewalt']==5\n",
    "# data3_5=data3[label_5]\n",
    "# train_5, test_5 = train_test_split(data3_5, test_size=25, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# train = pd.concat([train_0, train_1, train_2, train_3, train_4, train_5], axis=0)\n",
    "# test = pd.concat([test_0, test_1, test_2, test_3, test_4, test_5], axis=0)\n",
    "# print(pd.crosstab(index=train['Gewalt'], columns='count'))\n",
    "# print(pd.crosstab(index=test['Gewalt'], columns='count'))\n",
    "# # !pip install openpyxl\n",
    "\n",
    "\n",
    "# test.to_excel('Test_weitereBegriffe_Annotiert_20230607.xlsx',index=False)\n",
    "# from pathlib import Path  \n",
    "# filepath = Path('Test_weitereBegriffe_Annotiert_20230607.csv')  \n",
    "# filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "# test.to_csv(filepath)  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export of 5 sentences that do not linguistically involve violence, dichotomous classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0  count\n",
       "label       \n",
       "0        278\n",
       "1        484"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pd.crosstab(index=df['anotiert'], columns='count')\n",
    "# anotiert =  df3['anotiert']==1.0 \n",
    "gewaltsaetze_anotiert_sprachlich = train.copy()\n",
    "\n",
    "\n",
    "gewalt_num =     [0,1,2,3,4,5]\n",
    "gewalt_num_rec = [1,1,1,1,0,1]\n",
    "gewalt_string = [\"Satz hat sprachlich nicht mit Gewalt zu tun\", \"Satz hat sprachlich mit Gewalt zu tun\"]\n",
    "gewaltsaetze_anotiert_sprachlich['Gewalt'] = gewaltsaetze_anotiert_sprachlich['Gewalt'].replace(gewalt_num, gewalt_num_rec)\n",
    "\n",
    "# data0 = gewaltsaetze_anotiert_sprachlich[['Satz5_prep', 'Satz5', 'Satz5_prep', 'Gewalt']].copy()\n",
    "# temp_df= data0.copy()\n",
    "# temp_df['lenght'] = temp_df['Satz'].str.split().apply(len)\n",
    "# drop_50 =  temp_df['lenght']<=60\n",
    "# temp_df = temp_df[drop_50]\n",
    "\n",
    "data0 = gewaltsaetze_anotiert_sprachlich[['Satz5', 'Satz5_prep', 'Gewalt']].copy()\n",
    "data1=data0.rename(columns={\"Satz5\": \"sentence5\", \"Satz5_prep\": \"sentence5_prep\", \"Gewalt\": \"label\"}).copy()\n",
    "from pathlib import Path  \n",
    "filepath = Path('temp5_sprachlich_weitereBegriffe_20230607.csv')  \n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "data1.to_csv(filepath)  \n",
    "data1 = pd.read_csv('temp5_sprachlich_weitereBegriffe_20230607.csv',delimiter=',',encoding=\"utf\")\n",
    "# type(data1)\n",
    "pd.crosstab(index=data1['label'], columns='count')\n",
    "# from sklearn.utils import shuffle\n",
    "# temp=shuffle(data1)\n",
    "# temp[:50]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset of violent sentences, linguistically annotated, split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pwd\n",
    "# import the data\n",
    "#temp1_sprachlich = pd.read_csv(\"20210517_Predictive_Chance_Modelling_KJH_zhaw\\Arbeitsbereich_Dragan/temp1_sprachlich.csv\",delimiter=',',encoding=\"utf\")\n",
    "temp1_sprachlich = pd.read_csv(\"temp5_sprachlich_weitereBegriffe_20230607.csv\",delimiter=',',encoding=\"utf\")\n",
    "temp1_sprachlich=temp1_sprachlich.dropna()\n",
    "# temp1_sprachlich[temp1_sprachlich[\"sentence\"].isna()]\n",
    "\n",
    "pd.crosstab(index=temp1_sprachlich['label'], columns='count')\n",
    "from pathlib import Path  \n",
    "#filepath = Path('20210517_Predictive_Chance_Modelling_KJH_zhaw\\Arbeitsbereich_Dragan/gewalt_sprachlich_train_valid_datensatz_20230131.csv')  \n",
    "filepath = Path('gewalt_sprachlich_train_valid_datensatz_wB_20230607.csv')  \n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "temp1_sprachlich.to_csv(filepath)  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering the annotated classes, recoding the classes - excluding class 4 \"Sentence has no linguistic connection with..\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.crosstab(index=df3['anotiert'], columns='count')\n",
    "# anotiert =  df3['anotiert']==1.0 \n",
    "gewaltsaetze_anotiert = train.copy()\n",
    "#einsatz_prodoc = gewaltsaetze_anotiert['Nsatz']==1\n",
    "\n",
    "#gewaltsaetze_anotiert_einsatz = gewaltsaetze_anotiert[einsatz_prodoc]\n",
    "#gewaltsaetze_anotiert.head()\n",
    "# pd.crosstab(index=gewaltsaetze_anotiert['anotiert'], columns='count')\n",
    "#pd.crosstab(index=gewaltsaetze_anotiert_einsatz['Gewalt'], columns='count')\n",
    "#gewalt_num = [0,1,2,3,4]\n",
    "#gewalt_string = [\"Klient hat keine Gewalt erfahren\", \"Klient hat Gewalt erfahren\", \"Klient hat häusliche Gewalt erlebt\", \"Klient hat Gewalt ausgeübt\", \"Satz hat sprachlich nicht mit Gewalt zu tun\"]\n",
    "# recodierung ohne 'satz hat sprachlich nicht mit gewalt zu tun' \n",
    "drop_4 = gewaltsaetze_anotiert['Gewalt']!=4\n",
    "gewaltsaetze_anotiert = gewaltsaetze_anotiert[drop_4]\n",
    "# drop_6 = gewaltsaetze_anotiert['Gewalt']!=6\n",
    "# gewaltsaetze_anotiert = gewaltsaetze_anotiert[drop_6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gewalt</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0   count\n",
       "Gewalt       \n",
       "0         151\n",
       "1          65\n",
       "2          69\n",
       "3         134\n",
       "4          65"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "gewalt_num = [0,1,2,3,5]\n",
    "gewalt_num_rec = [0,1,2,3,4]\n",
    "gewalt_string = [\"Klient hat keine Gewalt erfahren\", \"Klient hat Gewalt erfahren\", \"Klient hat häusliche Gewalt erlebt\", \"Klient hat Gewalt ausgeübt\",  \"Satz hat sprachlich nicht mit Gewalt zu tun\", \"Klient hat sexuelle Gewalt erlebt\", \"Klient hat sexuelle Gewalt ausgeübt\"]\n",
    "gewaltsaetze_anotiert['Gewalt'] = gewaltsaetze_anotiert['Gewalt'].replace(gewalt_num, gewalt_num_rec)\n",
    "#gewaltsaetze_anotiert_einsatz.head()\n",
    "#gewaltsaetze_anotiert_einsatz.head(600)\n",
    "#gewaltsaetze_anotiert_einsatz['Satz_ohne_Gewalt'] = np.where(gewaltsaetze_anotiert_einsatz['Gewalt'] == 4, 1, 0)\n",
    "pd.crosstab(index=gewaltsaetze_anotiert['Gewalt'], columns='count')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating keywords for CARP classification (Clue Reasoning Prompting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(list(data3.columns))\n",
    "#create a new empty column \"clues\" \n",
    "# gewaltsaetze_anotiert['clues'] = \"\"\n",
    "#save  data3 df to excel file with the name \"negations_datensatz_für_clues_erstellung_20230714.xlsx\"\n",
    "from pathlib import Path\n",
    "filepath = Path('gewaltsaetze_anotiert_datensatz_für_clues_erstellung_20230714.xlsx')\n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)\n",
    "gewaltsaetze_anotiert.to_excel(filepath)\n",
    "\n",
    "#import the sheet1 from excel file \"gewaltsaetze_anotiert_datensatz_für_clues_erstellung_20230714_2.xlsx\" and save it as dataframe gewaltsaetze_anotiert_clues\n",
    "gewaltsaetze_anotiert_clues = pd.read_excel(\"gewaltsaetze_anotiert_datensatz_für_clues_erstellung_20230714_2.xlsx\", sheet_name=\"Sheet1\")\n",
    "#keep only columns Satz5, clues, reason and only rows with clues not empty\n",
    "gewaltsaetze_anotiert_clues = gewaltsaetze_anotiert_clues[['Satz5', 'clues', 'reason']].copy()\n",
    "gewaltsaetze_anotiert_clues = gewaltsaetze_anotiert_clues[gewaltsaetze_anotiert_clues['clues'].notna()]\n",
    "gewaltsaetze_anotiert_clues = gewaltsaetze_anotiert_clues[gewaltsaetze_anotiert_clues['reason'].notna()]\n",
    "#count number of rows\n",
    "# gewaltsaetze_anotiert_clues.shape\n",
    "#drop the column clues from gewaltsaetze_anotiert\n",
    "# gewaltsaetze_anotiert = gewaltsaetze_anotiert.drop(columns=['clues'])\n",
    "#merge gewaltsaetze_anotiert and gewaltsaetze_anotiert_clues on Satz5\n",
    "gewaltsaetze_anotiert2 = pd.merge(gewaltsaetze_anotiert, gewaltsaetze_anotiert_clues, left_on='Satz5', right_on='Satz5', how='left')\n",
    "# gewaltsaetze_anotiert.head(100)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export 5 Sätze Dataset temp5.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    151\n",
      "3    134\n",
      "2     69\n",
      "4     65\n",
      "1     65\n",
      "Name: Gewalt, dtype: int64\n",
      "3.0    13\n",
      "2.0     9\n",
      "5.0     5\n",
      "1.0     2\n",
      "Name: Gewalt_recoded, dtype: int64\n",
      "3    147\n",
      "0    122\n",
      "2     78\n",
      "4     70\n",
      "1     67\n",
      "Name: Gewalt, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#update recodierung der Gewaltklassen nach der Subklassifizierung\n",
    "\n",
    "# print(gewaltsaetze_anotiert2.columns)\n",
    "#print Gewalt column counts\n",
    "# print(gewaltsaetze_anotiert2['Gewalt'].value_counts())\n",
    "#read traindata_gewaltklassen_3bgrf_recoded_20230817.xlsx and save it a dataframe called gewaltklassen_recoded_subklassifiziert\n",
    "gewaltklassen_recoded_subklassifiziert = pd.read_excel('traindata_gewaltklassen_wbgrf_recoded_20230817.xlsx')\n",
    "#join gewaltklassen_recoded_subklassifiziert with gewaltsaetze_anotiert2 on the column 'Satz5' and save it as a new dataframe called gewaltsaetze_anotiert3\n",
    "gewaltsaetze_anotiert3 = gewaltsaetze_anotiert2.join(gewaltklassen_recoded_subklassifiziert.set_index('Satz5'), on='Satz5')\n",
    "# print(gewaltsaetze_anotiert3.columns)\n",
    "# print(gewaltsaetze_anotiert3.shape)\n",
    "print(gewaltsaetze_anotiert3['Gewalt'].value_counts())\n",
    "print(gewaltsaetze_anotiert3['Gewalt_recoded'].value_counts())\n",
    "#if Gewalt_recoded is 1 then recode Gewalt to 1\n",
    "gewaltsaetze_anotiert3.loc[gewaltsaetze_anotiert3['Gewalt_recoded'] == 1, 'Gewalt'] = 1\n",
    "#if Gewalt_recoded is 2 then recode Gewalt to 2\n",
    "gewaltsaetze_anotiert3.loc[gewaltsaetze_anotiert3['Gewalt_recoded'] == 2, 'Gewalt'] = 2\n",
    "#if Gewalt_recoded is 3 then recode Gewalt to 3\n",
    "gewaltsaetze_anotiert3.loc[gewaltsaetze_anotiert3['Gewalt_recoded'] == 3, 'Gewalt'] = 3\n",
    "\n",
    "#if Gewalt_recoded is 5 then recode Gewalt to 4\n",
    "gewaltsaetze_anotiert3.loc[gewaltsaetze_anotiert3['Gewalt_recoded'] == 5, 'Gewalt'] = 4\n",
    "\n",
    "print(gewaltsaetze_anotiert3['Gewalt'].value_counts())\n",
    "\n",
    "\n",
    "data0 = gewaltsaetze_anotiert3[['Satz5', 'Satz5_prep', 'Gewalt', 'clues', 'reason']].copy()\n",
    "data1=data0.rename(columns={\"Satz5\": \"sentence5\", \"Satz5_prep\": \"sentence5_prep\", \"Gewalt\": \"label\"}).copy()\n",
    "from pathlib import Path  \n",
    "filepath = Path('temp5_20230607.csv')  \n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "data1.to_csv(filepath)  \n",
    "data5 = pd.read_csv('temp5_20230607.csv',delimiter=',',encoding=\"utf\")\n",
    "type(data5)\n",
    "#counnt number of rows\n",
    "print(data5.shape)\n",
    "#list column names\n",
    "print(list(data5.columns))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Violent Sentences, annotated with negation/violence, split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0  count\n",
       "label       \n",
       "0        122\n",
       "1        362"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path    \n",
    "#data3 = pd.read_csv('20210517_Predictive_Chance_Modelling_KJH_zhaw\\Arbeitsbereich_Dragan/temp1.csv',delimiter=',',encoding=\"utf\")\n",
    "data3 = pd.read_csv('temp5_20230607.csv',delimiter=',',encoding=\"utf\")\n",
    "# data3=data3.dropna('label')\n",
    "# type(data3)\n",
    "# data3[data3[\"sentence\"].isna()]\n",
    "gewalt_num = [1,2,3, 4]\n",
    "gewalt_num_rec = [1,1,1, 1]\n",
    "data3['label'] = data3['label'].replace(gewalt_num, gewalt_num_rec)\n",
    "pd.crosstab(index=data3['label'], columns='count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data3 = data3.sample(frac=1).reset_index(drop=True)\n",
    "from pathlib import Path  \n",
    "#filepath = Path('20210517_Predictive_Chance_Modelling_KJH_zhaw\\Arbeitsbereich_Dragan/gewalt_negation_train_valid_datensatz_20230131.csv')  \n",
    "filepath = Path('gewalt_negation_train_valid_datensatz_wB_20230607.csv')  \n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "data3.to_csv(filepath)  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Violence Sentences, annotated  only violence, split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path    \n",
    "#data3 = pd.read_csv('20210517_Predictive_Chance_Modelling_KJH_zhaw\\Arbeitsbereich_Dragan/temp1.csv',delimiter=',',encoding=\"utf\")\n",
    "data3 = pd.read_csv('temp5_20230607.csv',delimiter=',',encoding=\"utf\")\n",
    "# data3=data3.dropna()\n",
    "# type(data3)\n",
    "# data3[data3[\"sentence\"].isna()]\n",
    "\n",
    "drop_0=data3['label']!=0\n",
    "data3=data3[drop_0]\n",
    "gewalt_num = [1,2,3,4]\n",
    "gewalt_num_rec = [0,1,2,3]\n",
    "data3['label'] = data3['label'].replace(gewalt_num, gewalt_num_rec)\n",
    "# print(pd.crosstab(index=data3['label'], columns='count'))\n",
    "\n",
    "\n",
    "\n",
    "data3 = data3.sample(frac=1).reset_index(drop=True)\n",
    "train_valid=data3.copy()\n",
    "# pd.crosstab(index=train_valid['label'], columns='count')\n",
    "from pathlib import Path  \n",
    "filepath = Path('gewalt_5ersaetze_train_valid_datensatz_wB_20230607.csv')  \n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "train_valid.to_csv(filepath)  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encrypting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required module\n",
    "from cryptography.fernet import Fernet\n",
    "import os\n",
    "\n",
    "# key generation\n",
    "# key = Fernet.generate_key()\n",
    "\n",
    "# string the key in a file\n",
    "# with open('filekey.key', 'wb') as filekey:\n",
    "#     filekey.write(key)\n",
    "\n",
    "# opening the key\n",
    "keytemp=os.path.expanduser('filekey.key')\n",
    "with open(keytemp, 'rb') as filekey:\n",
    "\tkey = filekey.read()\n",
    "\n",
    "print(key)\n",
    "\n",
    "# using the generated key\n",
    "fernet = Fernet(key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the original file to encrypt\n",
    "with open('gewalt_5ersaetze_train_valid_datensatz_wB_20230607.csv', 'rb') as file:\n",
    "\toriginal = file.read()\n",
    "\t\n",
    "# encrypting the file\n",
    "encrypted = fernet.encrypt(original)\n",
    "\n",
    "# opening the file in write mode and\n",
    "# writing the encrypted data\n",
    "with open('train5wbenc.csv', 'wb') as encrypted_file:\n",
    "\tencrypted_file.write(encrypted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# opening the original file to encrypt\n",
    "with open('gewalt_sprachlich_train_valid_datensatz_wB_20230607.csv', 'rb') as file:\n",
    "\toriginal = file.read()\n",
    "\t\n",
    "# encrypting the file\n",
    "encrypted = fernet.encrypt(original)\n",
    "\n",
    "# opening the file in write mode and\n",
    "# writing the encrypted data\n",
    "with open('train5wb_sprachlich_enc.csv', 'wb') as encrypted_file:\n",
    "\tencrypted_file.write(encrypted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# opening the original file to encrypt\n",
    "with open('gewalt_negation_train_valid_datensatz_wB_20230607.csv', 'rb') as file:\n",
    "\toriginal = file.read()\n",
    "\t\n",
    "# encrypting the file\n",
    "encrypted = fernet.encrypt(original)\n",
    "\n",
    "# opening the file in write mode and\n",
    "# writing the encrypted data\n",
    "with open('train5wb_negation_enc.csv', 'wb') as encrypted_file:\n",
    "\tencrypted_file.write(encrypted)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huggingface_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "036b9fb1130ac84a5bede25763fe06ea1f1f97943a6a1a32fbdde563ce2e1256"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
